<div class="main" style="margin-top: 5em">
  <h1 class="mat-h1">Fun little project</h1>
  Or, instead of tackling the 'open questions' which are more relevant to my PhD, could have a bit of fun with:

  <h1 class="mat-h1" id="maybe-drink">Maybe drink</h1>
  <p>/What are the chances</p>
  <h2 class="mat-h2" id="approach">Approach</h2>
  <ol type="1">
    <li>Take a map dataset</li>
    <li>Look for all coffee shops (or whatever) [and maybe population densities]</li>
    <li>Remove all coffee shops</li>
    <li>Based on population densities in zoning rules, infer if there is a coffeeshop</li>
  </ol>
  <h3 id="go-further">Go further</h3>
  <ol start="5" type="1">
    <li>Search for coffee</li>
    <li>Build an app</li>
    <li>As you’re walking/driving along, it’ll buzz and say “there probably a coffeeshop within 20 meters. 88.42%
      coffeeshop; 70% grocery shop”
    </li>
  </ol>
  <h3 id="generalise">Generalise</h3>
  <p>Actually let’s generalise to specifying a single drink you care about. Now it’s a find-me Lemonade app. Or a
    find-me Kombucha app.</p>
  <h2 class="mat-h2" id="deliverables">Deliverables</h2>
  <p>In the course will build:</p>
  <ol>
    <li>Fully functional neural network with a location->amenity dataset</li>
    <li>Fully functional mobile app</li>
    <li>Hacked-together scraper to quickly categorise a coffeeshop, but also include a simple NN for this task, to
      cluster keywords (for later search)
    </li>
    <li>Near-realtime integration with the map and the mobile’s GPS</li>
  </ol>
  <h2 class="mat-h2" id="data-science-topics">Data science topics</h2>
  <h3 id="natural-language-processing-nlp">Natural Language Processing (NLP)</h3>
  <ul>
    <li>NLP to categorise [disambiguate] drink based on country, e.g.: lemonade in Australia generally doesn’t refer to
      alcoholic beverages, whereas in America it does.
    </li>
  </ul>
  <h3 id="web-scraping">Web scraping</h3>
  <ul>
    <li>Given an OSM location, get the homepage, parse out the <code>&lt;head&gt;</code> and keyword search the body
    </li>
  </ul>
  <h3 id="multivariate-regression">Multivariate regression</h3>
  <ul>
    <li>Given a group of candidate stores, choose one most likely to have desired beverage</li>
  </ul>


  <hr>

  <h1 class="mat-h1">Open questions</h1>
  <p>There are a few machine-learning research questions that I'm trying to solve in the short-term.</p>

  <h2 class="mat-h2">Multivariate regression across medical images and patient records</h2>

  <h4>Idea 0</h4>
  <p>I was thinking that have a worker neural network doing the heavy lifting (maybe 3-5 NN all up) would do the
    trick. To keep epochs manageable, was thinking about the Meta-Learning and One-Shot Learning literature. But maybe
    that wouldn't
    work?</p>

  <p>Here is an excerpt from an email I sent to an AI expert recently:</p>
  <blockquote>
    <p>Hey so was thinking, if you have a secondary neural network for optimising the first neural network, couldn't you
      encode say image data in one, and patient data in another?</p>

    <p>Regularly we use multivariate regression—potentially via neural networking—on patient data to infer trends. For
      the problems I work on, these are risk factors for developing blindness-causing diseases.</p>

    <p>On the image side, I have a bunch of health and unhealthy images, and am currently just working out how to
      segment the classification correctly (more of the time). But it is longitudinal data, so could always combine it
      with information helping it say: these are healthy images for a patient that will become unhealthy.</p>

    <p>On the text side, I have general demographic information like gender, age, ethnicity and a few more specific [to
      glaucoma] metrics.</p>

    <p>How would you combine these two datasets? - Such that given a new person walking off the street, we can emit one
      number saying their probability of going blind in next k years (assuming no intervention).</p>

    <em>[multivariate regression over images and numerical patient data]</em>
  </blockquote>

  <h4>Idea 1</h4>
  <p>Or maybe adding an extra channel to a convolutional neural network?</p>

  <p>Encode the patient data in a hidden channel. Maybe figure out encoding with spatial relevant, or just hack
    specialised code for that last channel.</p>

  <h4>Idea 2</h4>
  <p>Jiquan Ngiam, Aditya Khosla, Mingyu Kim, Juhan Nam, Honglak Lee, and Andrew Y. Ng. 2011. Multimodal deep learning.
    In Proceedings of the 28th International Conference on International Conference on Machine Learning (ICML'11), Lise
    Getoor and Tobias Scheffer (Eds.). Omnipress, USA, 689-696.</p>

  <h2 class="mat-h2">Expand existing glaucoma AI</h2>
  Current Glaucoma CNN works on a non-public dataset (the <em>Blue Mountains Eye Study</em>).

  <h3>Idea 0: Transfer learning</h3>

  <h3>Idea 1: Incorporate public glaucoma datasets</h3>

  <h3>Idea 2: Incorporate NN for optic disc segmenetation</h3>
  Sevastopolsky A., Optic disc and cup segmentation methods for glaucoma detection with modification of U-Net
  convolutional neural network, Pattern Recognition and Image Analysis 27 (2017), no. 3, 618–624.

  <h3>Idea 3: Expand classifications to include Diabetic Retinopathy</h3>
  See Kaggle competition open-source solutions for concepts + datasets.
</div>
